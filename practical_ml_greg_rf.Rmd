---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Coursera - Practical Machine Learning - Course Project
```{r echo=TRUE}
library(ggplot2)
library(caret)
library(corrplot)
set.seed(1234)
```

# Import Data
```{r echo=TRUE}
test_set <- read.csv("pml-testing.csv", na.strings = c("NA", "", "#DIV/0!"))
train_set_orig <- read.csv("pml-training.csv", na.strings = c("NA", "", "#DIV/0!"))
inTrain <- createDataPartition(y = train_set_orig$classe, p = 0.7, list = F)
train_set <- train_set_orig[inTrain,]
valid_set <- train_set_orig[-inTrain,]
remove(inTrain)
dim(train_set)
```

# Distribution of response
Review distribution of the response variable.
```{r echo=TRUE}
ggplot(train_set_orig, aes(x=classe)) +
geom_bar(fill='red') +  labs(x='Classe Response Distribution')
```

# PreProcessing
## Near Zero Variance Predictors
Identify and remove near-zero-variance predictors as they do not contribute to the identification of patterns in the data. For this purpose we use function caret::nearZeroVar().
```{r echo=TRUE}
zeroVarIndices <- caret::nearZeroVar(train_set)
train_set <- train_set[, -zeroVarIndices]
remove(zeroVarIndices)
dim(train_set)
```

## Remove Predictors with too many NAs (missing data)
```{r echo=TRUE}
train_set <- train_set[,colMeans(is.na(train_set)) < .9]
dim(train_set)
```

## Reduce Collinearity
Collinearity is the situation where a pair of predictor variables have a substantial correlation with each other. In general, there are good reasons to avoid data with highly correlated predictors as it can result in highly unstable models and degraded predictive performance.

### Plot Correlations
The darker areas in the correlation plot show variables which are correlated with each other.
```{r echo=TRUE}
trn_numeric <- train_set[,sapply(train_set, is.numeric)]
correlations <- cor(trn_numeric)
corrplot::corrplot(correlations, order = "hclust",tl.cex = 0.5)
```

### Filter pairwise correlations
Dimension of dataset after removal of highly correlated predictors:
```{r echo=TRUE}
highCorr <- findCorrelation(correlations, cutoff = 0.75)
trn_numeric <- trn_numeric[, -highCorr]
remove(highCorr)
dim(trn_numeric)
```
Review correlation plot again:
```{r echo=TRUE}
correlations <- cor(trn_numeric)
corrplot::corrplot(correlations, order = "hclust",tl.cex = 0.5)
```
The darker areas have mostly disappeared as a result of having removed correlated predictors.

## Additional cleanup
```{r}
trn_numeric <- trn_numeric[, -c(1:3)]
```

# Random Forest
I leave train control on standard settings, i.e. function will run bootstrap resampling with 25 repetitions.
```{r}
remove(correlations)
# add back 'classe' to cleaned up data
trn_numeric$classe <- train_set$classe
# rf_mod_fit <- readRDS(file = "rf_mod_fit.rds")
if (!exists("rf_mod_fit")) {
    # initiate parallel processing as the process takes a long time
    library(doParallel)
    cl <- makePSOCKcluster(3)
    registerDoParallel(cl)
    # train the model
    rf_mod_fit <- train(classe ~ .,
                        data = trn_numeric,
                        method = "rf")
    stopCluster(cl)
    # save model
    saveRDS(rf_mod_fit, file = "rf_mod_fit.rds")
}
rf_mod_fit
```

Plot Random Forest Accuracy by Tuning Parameters
```{r}
plot(rf_mod_fit)
```

# Test Results on Validation Set
```{r}
valid_rf <- predict(rf_mod_fit, valid_set)
valid_conf_mtrx <- confusionMatrix(valid_rf, factor(valid_set$classe))
table(valid_set$classe)
table(valid_rf)
valid_conf_mtrx$table
```

# Predict on the Test Set
```{r echo=TRUE}
test_pred <- predict(rf_mod_fit, newdata = test_set)
print(test_pred)
# test_pred[1:5]
# test_pred[6:10]
# test_pred[11:15]
# test_pred[16:20]
```
